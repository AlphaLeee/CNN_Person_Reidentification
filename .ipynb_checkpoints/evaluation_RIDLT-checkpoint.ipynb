{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "caffe_root = '../'  \n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "\n",
    "import caffe\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "caffe.set_device(1)\n",
    "caffe.set_mode_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_def = './deploy/RIDLT.prototxt'\n",
    "model_weights = './models/RIDLT_iter_20000.caffemodel'\n",
    "testing_set = '/ssd/prp/data/prp_test.txt'\n",
    "num_test = 118\n",
    "length_library = 6817\n",
    "length_query = 13318-6817\n",
    "\n",
    "net = caffe.Net(model_def,      # defines the structure of the model\n",
    "                model_weights,  # contains the trained weights\n",
    "                caffe.TEST)     # use test mode (e.g., don't perform dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mu = np.load(caffe_root + 'python/caffe/imagenet/ilsvrc_2012_mean.npy')\n",
    "mu = mu.mean(1).mean(1)  # average over pixels to obtain the mean (BGR) pixel values\n",
    "\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "\n",
    "transformer.set_transpose('data', (2,0,1))  # move image channels to outermost dimension\n",
    "transformer.set_mean('data', mu)            # subtract the dataset-mean value in each channel\n",
    "transformer.set_raw_scale('data', 255)      # rescale from [0, 1] to [0, 255]\n",
    "transformer.set_channel_swap('data', (2,1,0))  # swap channels from RGB to BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.blobs['data'].reshape(batch_size, 3, 227, 227) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testfile=file(testing_set,'rb')\n",
    "imgs0=[]\n",
    "imgs1=[]\n",
    "feat0=[]\n",
    "feat1=[]\n",
    "for i in range(num_test):\n",
    "    imgs0.append([])\n",
    "    imgs1.append([])\n",
    "    feat0.append([])\n",
    "    feat1.append([])\n",
    "    \n",
    "for i in range(length_library):\n",
    "    line=testfile.readline()\n",
    "    imgs0[int(line.split()[1])].append(line.split()[0]) \n",
    "\n",
    "for i in range(length_query):\n",
    "    line=testfile.readline()\n",
    "    imgs1[int(line.split()[1])].append(line.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 25 0.04\n",
      "2 114 0.0175438596491\n",
      "3 60 0.05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5ff1d00ec1d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformed_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mj\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mfeat7\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fc7_m'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/prp/Caffe/caffe-master/python/caffe/pycaffe.pyc\u001b[0m in \u001b[0;36m_Net_forward\u001b[0;34m(self, blobs, start, end, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0min_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;31m# Unpack blobs to extract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "feat7_0_per=[]\n",
    "i=0\n",
    "for per in imgs0:\n",
    "    feat7_0_tmp=[]\n",
    "    batch_size=len(imgs0[i])\n",
    "    net.blobs['data'].reshape(batch_size, 3, 227, 227) \n",
    "    j=0\n",
    "    for img in imgs0[i]:\n",
    "        image = caffe.io.load_image(img)\n",
    "        transformed_image = transformer.preprocess('data', image)\n",
    "        net.blobs['data'].data[j] = transformed_image\n",
    "        j+=1\n",
    "    output = net.forward()\n",
    "    for k in range(batch_size):\n",
    "        feat7=net.blobs['fc7_m'].data[k]\n",
    "        feat7=feat7.tolist()\n",
    "        feat7_0_tmp.append(feat7)\n",
    "    feat7_0_per.append(feat7_0_tmp) \n",
    "    i+=1\n",
    "    print i,batch_size,float(i)/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feat7_1_per=[]\n",
    "i=0\n",
    "for per in imgs1:\n",
    "    feat7_1_tmp=[]\n",
    "    batch_size=len(imgs1[i])\n",
    "    net.blobs['data'].reshape(batch_size, 3, 227, 227) \n",
    "    j=0\n",
    "    for img in imgs1[i]:\n",
    "        image = caffe.io.load_image(img)\n",
    "        transformed_image = transformer.preprocess('data', image)\n",
    "        net.blobs['data'].data[j] = transformed_image\n",
    "        j+=1\n",
    "    output = net.forward()\n",
    "    for k in range(batch_size):\n",
    "        feat7=net.blobs['fc7_m'].data[k]\n",
    "        feat7=feat7.tolist()\n",
    "        feat7_1_tmp.append(feat7)\n",
    "    feat7_1_per.append(feat7_1_tmp)   \n",
    "    i+=1\n",
    "    print i/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat7_0_ave=[]\n",
    "for i in range(118):\n",
    "    img_sum=[0.0 for j in range(1024)]\n",
    "    img_sum=np.array(img_sum)\n",
    "    img_num=len(feat7_0_per[i])\n",
    "    t=0\n",
    "    for img in feat7_0_per[i]:\n",
    "        img=np.array(img)\n",
    "        img_sum+=img\n",
    "        t+=1    \n",
    "    img_sum/=img_num\n",
    "    img_sum=img_sum.tolist()\n",
    "    feat7_0_ave.append(img_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feat7_1_ave=[]\n",
    "for i in range(118):\n",
    "    img_sum=[0.0 for j in range(1024)]\n",
    "    img_sum=np.array(img_sum)\n",
    "    img_num=len(feat7_1_per[i])\n",
    "    t=0\n",
    "    for img in feat7_1_per[i]:\n",
    "        img=np.array(img)\n",
    "        img_sum+=img\n",
    "        t+=1    \n",
    "    img_sum/=img_num\n",
    "    img_sum=img_sum.tolist()\n",
    "    feat7_1_ave.append(img_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "sio.savemat('RIDLT_test_feature.mat',{'feat7_0_ave':feat7_0_ave,'feat7_1_ave':feat7_1_ave})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "description": "Instant recognition with a pre-trained model and a tour of the net interface for visualizing features and parameters layer-by-layer.",
  "example_name": "Image Classification and Filter Visualization",
  "include_in_docs": true,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "priority": 1
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
