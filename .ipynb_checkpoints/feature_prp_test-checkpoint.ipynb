{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "caffe_root = '../'  \n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "\n",
    "import caffe\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "caffe.set_device(1)\n",
    "caffe.set_mode_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_def = '/ssd/prp/deploy/imagenet_prp_deploy.prototxt'\n",
    "# model_def = caffe_root + 'models/deploy.prototxt'\n",
    "model_weights = './models/ILIDS_RIDLT_iter_40000.caffemodel'\n",
    "\n",
    "net = caffe.Net(model_def,      # defines the structure of the model\n",
    "                model_weights,  # contains the trained weights\n",
    "                caffe.TEST)     # use test mode (e.g., don't perform dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-subtracted values: [('B', 104.0069879317889), ('G', 116.66876761696767), ('R', 122.6789143406786)]\n"
     ]
    }
   ],
   "source": [
    "mu = np.load(caffe_root + 'python/caffe/imagenet/ilsvrc_2012_mean.npy')\n",
    "mu = mu.mean(1).mean(1)  # average over pixels to obtain the mean (BGR) pixel values\n",
    "print 'mean-subtracted values:', zip('BGR', mu)\n",
    "\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "\n",
    "transformer.set_transpose('data', (2,0,1))  # move image channels to outermost dimension\n",
    "transformer.set_mean('data', mu)            # subtract the dataset-mean value in each channel\n",
    "transformer.set_raw_scale('data', 255)      # rescale from [0, 1] to [0, 255]\n",
    "transformer.set_channel_swap('data', (2,1,0))  # swap channels from RGB to BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size=13318-6817\n",
    "\n",
    "net.blobs['data'].reshape(batch_size, 3, 227, 227) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testfile=file('/ssd/prp/data/prp_test.txt','rb')\n",
    "imgs0=[]\n",
    "imgs1=[]\n",
    "feat0=[]\n",
    "feat1=[]\n",
    "for i in range(118):\n",
    "    imgs0.append([])\n",
    "    imgs1.append([])\n",
    "    feat0.append([])\n",
    "    feat1.append([])\n",
    "    \n",
    "\n",
    "for i in range(6817):\n",
    "    line=testfile.readline()\n",
    "    imgs0[int(line.split()[1])].append(line.split()[0]) \n",
    "\n",
    "for i in range(13318-6817):\n",
    "    line=testfile.readline()\n",
    "    imgs1[int(line.split()[1])].append(line.split()[0])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n"
     ]
    }
   ],
   "source": [
    "feat7_0_per=[]\n",
    "i=0\n",
    "for per in imgs0:\n",
    "    feat7_0_tmp=[]\n",
    "    batch_size=len(imgs0[i])\n",
    "    net.blobs['data'].reshape(batch_size, 3, 227, 227) \n",
    "    j=0\n",
    "    for img in imgs0[i]:\n",
    "        image = caffe.io.load_image(img)\n",
    "        transformed_image = transformer.preprocess('data', image)\n",
    "        net.blobs['data'].data[j] = transformed_image\n",
    "        j+=1\n",
    "    output = net.forward()\n",
    "    for k in range(batch_size):\n",
    "        feat7=net.blobs['fc7_m'].data[k]\n",
    "        feat7=feat7.tolist()\n",
    "        feat7_0_tmp.append(feat7)\n",
    "    feat7_0_per.append(feat7_0_tmp)    \n",
    "    i+=1\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n"
     ]
    }
   ],
   "source": [
    "feat7_1_per=[]\n",
    "i=0\n",
    "for per in imgs1:\n",
    "    feat7_1_tmp=[]\n",
    "    batch_size=len(imgs1[i])\n",
    "    net.blobs['data'].reshape(batch_size, 3, 227, 227) \n",
    "    j=0\n",
    "    for img in imgs1[i]:\n",
    "        image = caffe.io.load_image(img)\n",
    "        transformed_image = transformer.preprocess('data', image)\n",
    "        net.blobs['data'].data[j] = transformed_image\n",
    "        j+=1\n",
    "    output = net.forward()\n",
    "    for k in range(batch_size):\n",
    "        feat7=net.blobs['fc7_m'].data[k]\n",
    "        feat7=feat7.tolist()\n",
    "        feat7_1_tmp.append(feat7)\n",
    "    feat7_1_per.append(feat7_1_tmp)   \n",
    "    i+=1\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat7_0_ave=[]\n",
    "for i in range(118):\n",
    "    img_sum=[0.0 for j in range(1024)]\n",
    "    img_sum=np.array(img_sum)\n",
    "    img_num=len(feat7_0_per[i])\n",
    "    t=0\n",
    "    for img in feat7_0_per[i]:\n",
    "        img=np.array(img)\n",
    "        img_sum+=img\n",
    "        t+=1    \n",
    "    img_sum/=img_num\n",
    "    img_sum=img_sum.tolist()\n",
    "    feat7_0_ave.append(img_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feat7_1_ave=[]\n",
    "for i in range(118):\n",
    "    img_sum=[0.0 for j in range(1024)]\n",
    "    img_sum=np.array(img_sum)\n",
    "    img_num=len(feat7_1_per[i])\n",
    "    t=0\n",
    "    for img in feat7_1_per[i]:\n",
    "        img=np.array(img)\n",
    "        img_sum+=img\n",
    "        t+=1    \n",
    "    img_sum/=img_num\n",
    "    img_sum=img_sum.tolist()\n",
    "    feat7_1_ave.append(img_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "sio.savemat('imagenet_prptest.mat',{'feat7_0_ave':feat7_0_ave,'feat7_1_ave':feat7_1_ave})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "description": "Instant recognition with a pre-trained model and a tour of the net interface for visualizing features and parameters layer-by-layer.",
  "example_name": "Image Classification and Filter Visualization",
  "include_in_docs": true,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "priority": 1
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
